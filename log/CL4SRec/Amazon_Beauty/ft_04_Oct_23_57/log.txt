04 Oct 23:57    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = ./dataset/Amazon_Beauty
show_progress = True

Training Hyper Parameters:
checkpoint_dir = saved
epochs = 50
train_batch_size = 256
learner = adam
learning_rate = 0.001
training_neg_sample_num = 0
training_neg_sample_distribution = uniform
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0
draw_loss_pic = False
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_setting = TO_LS,full
group_by_user = True
split_ratio = [0.8, 0.1, 0.1]
leave_one_num = 2
real_time_process = False
metrics = ['Recall', 'MRR', 'NDCG', 'Precision']
topk = [5, 10, 20, 50]
valid_metric = MRR@10
eval_batch_size = 256
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}
unload_col = None
unused_col = None
additional_feat_suffix = None
lowest_val = None
highest_val = None
equal_val = None
not_equal_val = None
max_user_inter_num = None
min_user_inter_num = 5
max_item_inter_num = None
min_item_inter_num = 5
fields_in_same_space = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id

Other Hyper Parameters: 
valid_metric_bigger = True
n_layers = 2
n_heads = 2
hidden_size = 64
inner_size = 256
hidden_dropout_prob = 0.5
attn_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
loss_type = CE
lmd = 0.1
SSL_AUG = CL4SRec
rm_dup_inter = None
filter_inter_by_user_or_item = True
SOURCE_ID_FIELD = source_id
TARGET_ID_FIELD = target_id
benchmark_filename = None
MODEL_TYPE = ModelType.SEQUENTIAL
log_root = ./log/
lmd_sem = 0.1
tau = 1
contrast = us_x
sim = dot
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
device = cuda
train_neg_sample_args = {'strategy': 'none'}
log_dir = /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5


04 Oct 23:57    INFO  Amazon_Beauty
The number of users: 22364
Average actions of users: 8.876358270357287
The number of items: 12102
Average actions of items: 16.403768283612923
The number of inters: 198502
The sparsity of the dataset: 99.92665707018277%
Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']
04 Oct 23:57    INFO  Build [SequentialDataLoader] for [train] with format [InputType.POINTWISE]
04 Oct 23:57    INFO  [train] No Negative Sampling
04 Oct 23:57    INFO  [train] batch_size = [256], shuffle = [True]

04 Oct 23:57    INFO  Build [SequentialFullDataLoader] for [evaluation] with format [InputType.POINTWISE]
04 Oct 23:57    INFO  Evaluation Setting:
	Group by user_id
	Ordering: {'strategy': 'by', 'field': 'timestamp', 'ascending': True}
	Splitting: {'strategy': 'loo', 'leave_one_num': 2}
	Negative Sampling: {'strategy': 'full', 'distribution': 'uniform'}
04 Oct 23:57    INFO  [evaluation] batch_size = [256], shuffle = [False]

04 Oct 23:57    INFO  CL4SRec(
  (item_embedding): Embedding(12103, 64, padding_idx=0)
  (position_embedding): Embedding(50, 64)
  (trm_encoder): TransformerEncoder(
    (layer): ModuleList(
      (0-1): 2 x TransformerLayer(
        (multi_head_attention): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (loss_fct): CrossEntropyLoss()
  (nce_fct): CrossEntropyLoss()
)
Trainable parameters: 877888
Train     0: 100% 514/514 [00:36<00:00, 13.90it/s]
04 Oct 23:58    INFO  epoch 0 training [time: 37.14s, train_loss1: 4871.4293, train_loss2: 2758.2912, train_loss3: -6212.5545]
Evaluate   : 100% 88/88 [00:00<00:00, 162.50it/s]
04 Oct 23:58    INFO  epoch 0 evaluating [time: 0.71s, valid_score: 0.008400]
04 Oct 23:58    INFO  valid result: 
recall@5 : 0.0158    recall@10 : 0.0258    recall@20 : 0.0377    recall@50 : 0.066    mrr@5 : 0.0071    mrr@10 : 0.0084    mrr@20 : 0.0092    mrr@50 : 0.0101    ndcg@5 : 0.0092    ndcg@10 : 0.0125    ndcg@20 : 0.0154    ndcg@50 : 0.021    precision@5 : 0.0032    precision@10 : 0.0026    precision@20 : 0.0019    precision@50 : 0.0013    
04 Oct 23:58    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     1: 100% 514/514 [00:37<00:00, 13.79it/s]
04 Oct 23:59    INFO  epoch 1 training [time: 37.44s, train_loss1: 4547.8934, train_loss2: 2382.0353, train_loss3: -5720.6061]
Evaluate   : 100% 88/88 [00:00<00:00, 172.00it/s]
04 Oct 23:59    INFO  epoch 1 evaluating [time: 0.65s, valid_score: 0.012300]
04 Oct 23:59    INFO  valid result: 
recall@5 : 0.0189    recall@10 : 0.0363    recall@20 : 0.0567    recall@50 : 0.0962    mrr@5 : 0.0099    mrr@10 : 0.0123    mrr@20 : 0.0136    mrr@50 : 0.0149    ndcg@5 : 0.0121    ndcg@10 : 0.0178    ndcg@20 : 0.0229    ndcg@50 : 0.0308    precision@5 : 0.0038    precision@10 : 0.0036    precision@20 : 0.0028    precision@50 : 0.0019    
04 Oct 23:59    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     2: 100% 514/514 [00:36<00:00, 14.24it/s]
04 Oct 23:59    INFO  epoch 2 training [time: 36.25s, train_loss1: 4394.4050, train_loss2: 2463.6363, train_loss3: -5993.7438]
Evaluate   : 100% 88/88 [00:00<00:00, 171.56it/s]
04 Oct 23:59    INFO  epoch 2 evaluating [time: 0.67s, valid_score: 0.014900]
04 Oct 23:59    INFO  valid result: 
recall@5 : 0.0254    recall@10 : 0.0451    recall@20 : 0.0702    recall@50 : 0.1187    mrr@5 : 0.0123    mrr@10 : 0.0149    mrr@20 : 0.0166    mrr@50 : 0.0181    ndcg@5 : 0.0155    ndcg@10 : 0.0218    ndcg@20 : 0.0281    ndcg@50 : 0.0377    precision@5 : 0.0051    precision@10 : 0.0045    precision@20 : 0.0035    precision@50 : 0.0024    
04 Oct 23:59    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     3: 100% 514/514 [00:36<00:00, 14.07it/s]
05 Oct 00:00    INFO  epoch 3 training [time: 36.70s, train_loss1: 4290.7566, train_loss2: 2537.2506, train_loss3: -6198.5151]
Evaluate   : 100% 88/88 [00:00<00:00, 171.65it/s]
05 Oct 00:00    INFO  epoch 3 evaluating [time: 0.67s, valid_score: 0.017600]
05 Oct 00:00    INFO  valid result: 
recall@5 : 0.0297    recall@10 : 0.0498    recall@20 : 0.0787    recall@50 : 0.1347    mrr@5 : 0.015    mrr@10 : 0.0176    mrr@20 : 0.0196    mrr@50 : 0.0213    ndcg@5 : 0.0186    ndcg@10 : 0.0251    ndcg@20 : 0.0323    ndcg@50 : 0.0433    precision@5 : 0.0059    precision@10 : 0.005    precision@20 : 0.0039    precision@50 : 0.0027    
05 Oct 00:00    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     4: 100% 514/514 [00:36<00:00, 13.93it/s]
05 Oct 00:01    INFO  epoch 4 training [time: 37.07s, train_loss1: 4225.3202, train_loss2: 2585.6590, train_loss3: -6292.7513]
Evaluate   : 100% 88/88 [00:00<00:00, 171.31it/s]
05 Oct 00:01    INFO  epoch 4 evaluating [time: 0.65s, valid_score: 0.018300]
05 Oct 00:01    INFO  valid result: 
recall@5 : 0.0302    recall@10 : 0.0528    recall@20 : 0.0822    recall@50 : 0.1394    mrr@5 : 0.0153    mrr@10 : 0.0183    mrr@20 : 0.0203    mrr@50 : 0.0221    ndcg@5 : 0.019    ndcg@10 : 0.0263    ndcg@20 : 0.0337    ndcg@50 : 0.0449    precision@5 : 0.006    precision@10 : 0.0053    precision@20 : 0.0041    precision@50 : 0.0028    
05 Oct 00:01    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     5: 100% 514/514 [00:36<00:00, 14.19it/s]
05 Oct 00:01    INFO  epoch 5 training [time: 36.40s, train_loss1: 4179.9322, train_loss2: 2616.4087, train_loss3: -6242.6443]
Evaluate   : 100% 88/88 [00:00<00:00, 172.13it/s]
05 Oct 00:01    INFO  epoch 5 evaluating [time: 0.66s, valid_score: 0.019700]
05 Oct 00:01    INFO  valid result: 
recall@5 : 0.0335    recall@10 : 0.0569    recall@20 : 0.088    recall@50 : 0.1488    mrr@5 : 0.0167    mrr@10 : 0.0197    mrr@20 : 0.0219    mrr@50 : 0.0238    ndcg@5 : 0.0208    ndcg@10 : 0.0283    ndcg@20 : 0.0362    ndcg@50 : 0.0482    precision@5 : 0.0067    precision@10 : 0.0057    precision@20 : 0.0044    precision@50 : 0.003    
05 Oct 00:01    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     6: 100% 514/514 [00:36<00:00, 14.16it/s]
05 Oct 00:02    INFO  epoch 6 training [time: 36.47s, train_loss1: 4149.6972, train_loss2: 2635.8077, train_loss3: -6095.5020]
Evaluate   : 100% 88/88 [00:00<00:00, 172.33it/s]
05 Oct 00:02    INFO  epoch 6 evaluating [time: 0.65s, valid_score: 0.020400]
05 Oct 00:02    INFO  valid result: 
recall@5 : 0.0364    recall@10 : 0.0597    recall@20 : 0.0942    recall@50 : 0.1582    mrr@5 : 0.0174    mrr@10 : 0.0204    mrr@20 : 0.0228    mrr@50 : 0.0247    ndcg@5 : 0.0221    ndcg@10 : 0.0295    ndcg@20 : 0.0382    ndcg@50 : 0.0508    precision@5 : 0.0073    precision@10 : 0.006    precision@20 : 0.0047    precision@50 : 0.0032    
05 Oct 00:02    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     7: 100% 514/514 [00:37<00:00, 13.80it/s]
05 Oct 00:02    INFO  epoch 7 training [time: 37.42s, train_loss1: 4127.1413, train_loss2: 2644.4856, train_loss3: -5874.7240]
Evaluate   : 100% 88/88 [00:00<00:00, 164.01it/s]
05 Oct 00:02    INFO  epoch 7 evaluating [time: 0.75s, valid_score: 0.022000]
05 Oct 00:02    INFO  valid result: 
recall@5 : 0.0388    recall@10 : 0.0625    recall@20 : 0.0978    recall@50 : 0.163    mrr@5 : 0.0189    mrr@10 : 0.022    mrr@20 : 0.0245    mrr@50 : 0.0265    ndcg@5 : 0.0238    ndcg@10 : 0.0314    ndcg@20 : 0.0403    ndcg@50 : 0.0532    precision@5 : 0.0078    precision@10 : 0.0063    precision@20 : 0.0049    precision@50 : 0.0033    
05 Oct 00:02    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     8: 100% 514/514 [00:36<00:00, 14.17it/s]
05 Oct 00:03    INFO  epoch 8 training [time: 36.50s, train_loss1: 4111.2299, train_loss2: 2648.9745, train_loss3: -5636.7641]
Evaluate   : 100% 88/88 [00:00<00:00, 160.77it/s]
05 Oct 00:03    INFO  epoch 8 evaluating [time: 0.76s, valid_score: 0.023200]
05 Oct 00:03    INFO  valid result: 
recall@5 : 0.0416    recall@10 : 0.0659    recall@20 : 0.1007    recall@50 : 0.1655    mrr@5 : 0.02    mrr@10 : 0.0232    mrr@20 : 0.0255    mrr@50 : 0.0276    ndcg@5 : 0.0253    ndcg@10 : 0.0331    ndcg@20 : 0.0418    ndcg@50 : 0.0546    precision@5 : 0.0083    precision@10 : 0.0066    precision@20 : 0.005    precision@50 : 0.0033    
05 Oct 00:03    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     9: 100% 514/514 [00:36<00:00, 14.09it/s]
05 Oct 00:04    INFO  epoch 9 training [time: 36.65s, train_loss1: 4100.9059, train_loss2: 2650.7105, train_loss3: -5403.8301]
Evaluate   : 100% 88/88 [00:00<00:00, 171.65it/s]
05 Oct 00:04    INFO  epoch 9 evaluating [time: 0.65s, valid_score: 0.024100]
05 Oct 00:04    INFO  valid result: 
recall@5 : 0.0413    recall@10 : 0.0678    recall@20 : 0.1032    recall@50 : 0.17    mrr@5 : 0.0206    mrr@10 : 0.0241    mrr@20 : 0.0265    mrr@50 : 0.0286    ndcg@5 : 0.0256    ndcg@10 : 0.0342    ndcg@20 : 0.0431    ndcg@50 : 0.0563    precision@5 : 0.0083    precision@10 : 0.0068    precision@20 : 0.0052    precision@50 : 0.0034    
05 Oct 00:04    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    10: 100% 514/514 [00:37<00:00, 13.89it/s]
05 Oct 00:04    INFO  epoch 10 training [time: 37.18s, train_loss1: 4093.5798, train_loss2: 2644.9788, train_loss3: -5196.7923]
Evaluate   : 100% 88/88 [00:00<00:00, 171.50it/s]
05 Oct 00:04    INFO  epoch 10 evaluating [time: 0.65s, valid_score: 0.022500]
05 Oct 00:04    INFO  valid result: 
recall@5 : 0.041    recall@10 : 0.0672    recall@20 : 0.103    recall@50 : 0.171    mrr@5 : 0.019    mrr@10 : 0.0225    mrr@20 : 0.025    mrr@50 : 0.0271    ndcg@5 : 0.0244    ndcg@10 : 0.0329    ndcg@20 : 0.0419    ndcg@50 : 0.0553    precision@5 : 0.0082    precision@10 : 0.0067    precision@20 : 0.0052    precision@50 : 0.0034    
Train    11: 100% 514/514 [00:36<00:00, 14.08it/s]
05 Oct 00:05    INFO  epoch 11 training [time: 36.68s, train_loss1: 4087.8431, train_loss2: 2638.4385, train_loss3: -5011.3501]
Evaluate   : 100% 88/88 [00:00<00:00, 171.35it/s]
05 Oct 00:05    INFO  epoch 11 evaluating [time: 0.67s, valid_score: 0.023300]
05 Oct 00:05    INFO  valid result: 
recall@5 : 0.0424    recall@10 : 0.0686    recall@20 : 0.1041    recall@50 : 0.171    mrr@5 : 0.0199    mrr@10 : 0.0233    mrr@20 : 0.0257    mrr@50 : 0.0278    ndcg@5 : 0.0254    ndcg@10 : 0.0338    ndcg@20 : 0.0427    ndcg@50 : 0.0559    precision@5 : 0.0085    precision@10 : 0.0069    precision@20 : 0.0052    precision@50 : 0.0034    
Train    12: 100% 514/514 [00:36<00:00, 14.13it/s]
05 Oct 00:06    INFO  epoch 12 training [time: 36.55s, train_loss1: 4083.6926, train_loss2: 2628.2093, train_loss3: -4848.5741]
Evaluate   : 100% 88/88 [00:00<00:00, 172.38it/s]
05 Oct 00:06    INFO  epoch 12 evaluating [time: 0.65s, valid_score: 0.022900]
05 Oct 00:06    INFO  valid result: 
recall@5 : 0.0425    recall@10 : 0.0686    recall@20 : 0.1071    recall@50 : 0.1727    mrr@5 : 0.0195    mrr@10 : 0.0229    mrr@20 : 0.0255    mrr@50 : 0.0276    ndcg@5 : 0.0251    ndcg@10 : 0.0335    ndcg@20 : 0.0432    ndcg@50 : 0.0561    precision@5 : 0.0085    precision@10 : 0.0069    precision@20 : 0.0054    precision@50 : 0.0035    
Train    13: 100% 514/514 [00:36<00:00, 13.95it/s]
05 Oct 00:06    INFO  epoch 13 training [time: 37.04s, train_loss1: 4079.5816, train_loss2: 2624.4376, train_loss3: -4709.9026]
Evaluate   : 100% 88/88 [00:00<00:00, 171.26it/s]
05 Oct 00:06    INFO  epoch 13 evaluating [time: 0.65s, valid_score: 0.024700]
05 Oct 00:06    INFO  valid result: 
recall@5 : 0.0456    recall@10 : 0.0728    recall@20 : 0.1088    recall@50 : 0.1735    mrr@5 : 0.0211    mrr@10 : 0.0247    mrr@20 : 0.0271    mrr@50 : 0.0291    ndcg@5 : 0.0271    ndcg@10 : 0.0358    ndcg@20 : 0.0448    ndcg@50 : 0.0577    precision@5 : 0.0091    precision@10 : 0.0073    precision@20 : 0.0054    precision@50 : 0.0035    
05 Oct 00:06    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    14: 100% 514/514 [00:36<00:00, 14.19it/s]
05 Oct 00:07    INFO  epoch 14 training [time: 36.38s, train_loss1: 4075.3767, train_loss2: 2620.2725, train_loss3: -4622.9125]
Evaluate   : 100% 88/88 [00:00<00:00, 171.79it/s]
05 Oct 00:07    INFO  epoch 14 evaluating [time: 0.65s, valid_score: 0.023800]
05 Oct 00:07    INFO  valid result: 
recall@5 : 0.044    recall@10 : 0.0718    recall@20 : 0.1075    recall@50 : 0.1727    mrr@5 : 0.0201    mrr@10 : 0.0238    mrr@20 : 0.0262    mrr@50 : 0.0282    ndcg@5 : 0.026    ndcg@10 : 0.0349    ndcg@20 : 0.0439    ndcg@50 : 0.0568    precision@5 : 0.0088    precision@10 : 0.0072    precision@20 : 0.0054    precision@50 : 0.0035    
Train    15: 100% 514/514 [00:36<00:00, 14.18it/s]
05 Oct 00:07    INFO  epoch 15 training [time: 36.41s, train_loss1: 4072.3156, train_loss2: 2611.6741, train_loss3: -4513.5003]
Evaluate   : 100% 88/88 [00:00<00:00, 171.07it/s]
05 Oct 00:07    INFO  epoch 15 evaluating [time: 0.66s, valid_score: 0.023600]
05 Oct 00:07    INFO  valid result: 
recall@5 : 0.0437    recall@10 : 0.0712    recall@20 : 0.1076    recall@50 : 0.1732    mrr@5 : 0.02    mrr@10 : 0.0236    mrr@20 : 0.0261    mrr@50 : 0.0282    ndcg@5 : 0.0258    ndcg@10 : 0.0347    ndcg@20 : 0.0438    ndcg@50 : 0.0568    precision@5 : 0.0087    precision@10 : 0.0071    precision@20 : 0.0054    precision@50 : 0.0035    
Train    16: 100% 514/514 [00:37<00:00, 13.83it/s]
05 Oct 00:08    INFO  epoch 16 training [time: 37.33s, train_loss1: 4068.1773, train_loss2: 2607.8214, train_loss3: -4439.1339]
Evaluate   : 100% 88/88 [00:00<00:00, 170.96it/s]
05 Oct 00:08    INFO  epoch 16 evaluating [time: 0.66s, valid_score: 0.024300]
05 Oct 00:08    INFO  valid result: 
recall@5 : 0.045    recall@10 : 0.0735    recall@20 : 0.1079    recall@50 : 0.1735    mrr@5 : 0.0206    mrr@10 : 0.0243    mrr@20 : 0.0267    mrr@50 : 0.0287    ndcg@5 : 0.0266    ndcg@10 : 0.0357    ndcg@20 : 0.0444    ndcg@50 : 0.0573    precision@5 : 0.009    precision@10 : 0.0074    precision@20 : 0.0054    precision@50 : 0.0035    
Train    17: 100% 514/514 [00:36<00:00, 14.16it/s]
05 Oct 00:09    INFO  epoch 17 training [time: 36.46s, train_loss1: 4060.2454, train_loss2: 2602.4052, train_loss3: -4382.6433]
Evaluate   : 100% 88/88 [00:00<00:00, 171.08it/s]
05 Oct 00:09    INFO  epoch 17 evaluating [time: 0.66s, valid_score: 0.024400]
05 Oct 00:09    INFO  valid result: 
recall@5 : 0.0472    recall@10 : 0.0732    recall@20 : 0.1099    recall@50 : 0.1729    mrr@5 : 0.0209    mrr@10 : 0.0244    mrr@20 : 0.0269    mrr@50 : 0.0289    ndcg@5 : 0.0274    ndcg@10 : 0.0358    ndcg@20 : 0.045    ndcg@50 : 0.0575    precision@5 : 0.0094    precision@10 : 0.0073    precision@20 : 0.0055    precision@50 : 0.0035    
Train    18: 100% 514/514 [00:36<00:00, 14.21it/s]
05 Oct 00:09    INFO  epoch 18 training [time: 36.34s, train_loss1: 4056.3693, train_loss2: 2598.9983, train_loss3: -4317.7261]
Evaluate   : 100% 88/88 [00:00<00:00, 172.18it/s]
05 Oct 00:09    INFO  epoch 18 evaluating [time: 0.65s, valid_score: 0.024700]
05 Oct 00:09    INFO  valid result: 
recall@5 : 0.045    recall@10 : 0.0745    recall@20 : 0.1099    recall@50 : 0.1752    mrr@5 : 0.0208    mrr@10 : 0.0247    mrr@20 : 0.0271    mrr@50 : 0.0292    ndcg@5 : 0.0267    ndcg@10 : 0.0362    ndcg@20 : 0.0452    ndcg@50 : 0.0581    precision@5 : 0.009    precision@10 : 0.0074    precision@20 : 0.0055    precision@50 : 0.0035    
Train    19: 100% 514/514 [00:36<00:00, 13.99it/s]
05 Oct 00:10    INFO  epoch 19 training [time: 36.90s, train_loss1: 4048.7691, train_loss2: 2589.1437, train_loss3: -4256.1652]
Evaluate   : 100% 88/88 [00:00<00:00, 172.05it/s]
05 Oct 00:10    INFO  epoch 19 evaluating [time: 0.66s, valid_score: 0.023800]
05 Oct 00:10    INFO  valid result: 
recall@5 : 0.0457    recall@10 : 0.0734    recall@20 : 0.1083    recall@50 : 0.1737    mrr@5 : 0.0202    mrr@10 : 0.0238    mrr@20 : 0.0262    mrr@50 : 0.0283    ndcg@5 : 0.0265    ndcg@10 : 0.0354    ndcg@20 : 0.0441    ndcg@50 : 0.0571    precision@5 : 0.0091    precision@10 : 0.0073    precision@20 : 0.0054    precision@50 : 0.0035    
Train    20: 100% 514/514 [00:36<00:00, 14.16it/s]
05 Oct 00:11    INFO  epoch 20 training [time: 36.48s, train_loss1: 4043.0276, train_loss2: 2589.1044, train_loss3: -4207.9302]
Evaluate   : 100% 88/88 [00:00<00:00, 171.08it/s]
05 Oct 00:11    INFO  epoch 20 evaluating [time: 0.70s, valid_score: 0.024000]
05 Oct 00:11    INFO  valid result: 
recall@5 : 0.046    recall@10 : 0.0746    recall@20 : 0.1092    recall@50 : 0.1739    mrr@5 : 0.0202    mrr@10 : 0.024    mrr@20 : 0.0264    mrr@50 : 0.0284    ndcg@5 : 0.0265    ndcg@10 : 0.0358    ndcg@20 : 0.0445    ndcg@50 : 0.0573    precision@5 : 0.0092    precision@10 : 0.0075    precision@20 : 0.0055    precision@50 : 0.0035    
Train    21: 100% 514/514 [00:36<00:00, 14.17it/s]
05 Oct 00:11    INFO  epoch 21 training [time: 36.52s, train_loss1: 4035.1421, train_loss2: 2579.1163, train_loss3: -4164.3223]
Evaluate   : 100% 88/88 [00:00<00:00, 164.87it/s]
05 Oct 00:11    INFO  epoch 21 evaluating [time: 0.76s, valid_score: 0.023900]
05 Oct 00:11    INFO  valid result: 
recall@5 : 0.046    recall@10 : 0.0745    recall@20 : 0.1098    recall@50 : 0.1749    mrr@5 : 0.0202    mrr@10 : 0.0239    mrr@20 : 0.0264    mrr@50 : 0.0284    ndcg@5 : 0.0265    ndcg@10 : 0.0357    ndcg@20 : 0.0446    ndcg@50 : 0.0575    precision@5 : 0.0092    precision@10 : 0.0074    precision@20 : 0.0055    precision@50 : 0.0035    
Train    22: 100% 514/514 [00:37<00:00, 13.86it/s]
05 Oct 00:12    INFO  epoch 22 training [time: 37.30s, train_loss1: 4027.5205, train_loss2: 2574.3766, train_loss3: -4119.8053]
Evaluate   : 100% 88/88 [00:00<00:00, 166.24it/s]
05 Oct 00:12    INFO  epoch 22 evaluating [time: 0.67s, valid_score: 0.023400]
05 Oct 00:12    INFO  valid result: 
recall@5 : 0.0457    recall@10 : 0.0741    recall@20 : 0.1071    recall@50 : 0.1734    mrr@5 : 0.0197    mrr@10 : 0.0234    mrr@20 : 0.0257    mrr@50 : 0.0278    ndcg@5 : 0.0261    ndcg@10 : 0.0352    ndcg@20 : 0.0435    ndcg@50 : 0.0566    precision@5 : 0.0091    precision@10 : 0.0074    precision@20 : 0.0054    precision@50 : 0.0035    
Train    23: 100% 514/514 [00:36<00:00, 14.17it/s]
05 Oct 00:12    INFO  epoch 23 training [time: 36.44s, train_loss1: 4017.5032, train_loss2: 2571.2687, train_loss3: -4088.8430]
Evaluate   : 100% 88/88 [00:00<00:00, 171.52it/s]
05 Oct 00:12    INFO  epoch 23 evaluating [time: 0.66s, valid_score: 0.024800]
05 Oct 00:12    INFO  valid result: 
recall@5 : 0.048    recall@10 : 0.0759    recall@20 : 0.11    recall@50 : 0.1764    mrr@5 : 0.0211    mrr@10 : 0.0248    mrr@20 : 0.0271    mrr@50 : 0.0292    ndcg@5 : 0.0277    ndcg@10 : 0.0367    ndcg@20 : 0.0453    ndcg@50 : 0.0584    precision@5 : 0.0096    precision@10 : 0.0076    precision@20 : 0.0055    precision@50 : 0.0035    
05 Oct 00:12    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    24: 100% 514/514 [00:36<00:00, 14.09it/s]
05 Oct 00:13    INFO  epoch 24 training [time: 36.65s, train_loss1: 4010.9211, train_loss2: 2565.1798, train_loss3: -4045.5198]
Evaluate   : 100% 88/88 [00:00<00:00, 171.31it/s]
05 Oct 00:13    INFO  epoch 24 evaluating [time: 0.66s, valid_score: 0.023500]
05 Oct 00:13    INFO  valid result: 
recall@5 : 0.0468    recall@10 : 0.0746    recall@20 : 0.1091    recall@50 : 0.1728    mrr@5 : 0.0198    mrr@10 : 0.0235    mrr@20 : 0.0258    mrr@50 : 0.0278    ndcg@5 : 0.0264    ndcg@10 : 0.0354    ndcg@20 : 0.0441    ndcg@50 : 0.0567    precision@5 : 0.0094    precision@10 : 0.0075    precision@20 : 0.0055    precision@50 : 0.0035    
Train    25: 100% 514/514 [00:36<00:00, 13.94it/s]
05 Oct 00:14    INFO  epoch 25 training [time: 37.04s, train_loss1: 4003.2180, train_loss2: 2561.3384, train_loss3: -4035.4614]
Evaluate   : 100% 88/88 [00:00<00:00, 170.99it/s]
05 Oct 00:14    INFO  epoch 25 evaluating [time: 0.66s, valid_score: 0.023600]
05 Oct 00:14    INFO  valid result: 
recall@5 : 0.047    recall@10 : 0.0756    recall@20 : 0.1097    recall@50 : 0.1748    mrr@5 : 0.0198    mrr@10 : 0.0236    mrr@20 : 0.0259    mrr@50 : 0.028    ndcg@5 : 0.0264    ndcg@10 : 0.0357    ndcg@20 : 0.0443    ndcg@50 : 0.0572    precision@5 : 0.0094    precision@10 : 0.0076    precision@20 : 0.0055    precision@50 : 0.0035    
Train    26: 100% 514/514 [00:36<00:00, 14.15it/s]
05 Oct 00:14    INFO  epoch 26 training [time: 36.50s, train_loss1: 3995.3608, train_loss2: 2551.1330, train_loss3: -3991.8625]
Evaluate   : 100% 88/88 [00:00<00:00, 171.33it/s]
05 Oct 00:14    INFO  epoch 26 evaluating [time: 0.67s, valid_score: 0.023800]
05 Oct 00:14    INFO  valid result: 
recall@5 : 0.0471    recall@10 : 0.077    recall@20 : 0.1109    recall@50 : 0.1735    mrr@5 : 0.0199    mrr@10 : 0.0238    mrr@20 : 0.0261    mrr@50 : 0.028    ndcg@5 : 0.0266    ndcg@10 : 0.0362    ndcg@20 : 0.0447    ndcg@50 : 0.0571    precision@5 : 0.0094    precision@10 : 0.0077    precision@20 : 0.0055    precision@50 : 0.0035    
Train    27: 100% 514/514 [00:36<00:00, 14.15it/s]
05 Oct 00:15    INFO  epoch 27 training [time: 36.49s, train_loss1: 3986.1738, train_loss2: 2542.7121, train_loss3: -3947.2145]
Evaluate   : 100% 88/88 [00:00<00:00, 171.95it/s]
05 Oct 00:15    INFO  epoch 27 evaluating [time: 0.66s, valid_score: 0.024400]
05 Oct 00:15    INFO  valid result: 
recall@5 : 0.0476    recall@10 : 0.0757    recall@20 : 0.1095    recall@50 : 0.1744    mrr@5 : 0.0206    mrr@10 : 0.0244    mrr@20 : 0.0267    mrr@50 : 0.0288    ndcg@5 : 0.0273    ndcg@10 : 0.0364    ndcg@20 : 0.0449    ndcg@50 : 0.0578    precision@5 : 0.0095    precision@10 : 0.0076    precision@20 : 0.0055    precision@50 : 0.0035    
Train    28: 100% 514/514 [00:37<00:00, 13.84it/s]
05 Oct 00:16    INFO  epoch 28 training [time: 37.32s, train_loss1: 3982.0023, train_loss2: 2536.6778, train_loss3: -3944.0017]
Evaluate   : 100% 88/88 [00:00<00:00, 170.05it/s]
05 Oct 00:16    INFO  epoch 28 evaluating [time: 0.67s, valid_score: 0.023700]
05 Oct 00:16    INFO  valid result: 
recall@5 : 0.0474    recall@10 : 0.0744    recall@20 : 0.1092    recall@50 : 0.1722    mrr@5 : 0.0201    mrr@10 : 0.0237    mrr@20 : 0.0261    mrr@50 : 0.0281    ndcg@5 : 0.0269    ndcg@10 : 0.0355    ndcg@20 : 0.0443    ndcg@50 : 0.0568    precision@5 : 0.0095    precision@10 : 0.0074    precision@20 : 0.0055    precision@50 : 0.0034    
Train    29: 100% 514/514 [00:36<00:00, 14.16it/s]
05 Oct 00:16    INFO  epoch 29 training [time: 36.47s, train_loss1: 3970.5176, train_loss2: 2528.0533, train_loss3: -3915.0769]
Evaluate   : 100% 88/88 [00:00<00:00, 171.77it/s]
05 Oct 00:16    INFO  epoch 29 evaluating [time: 0.66s, valid_score: 0.023800]
05 Oct 00:16    INFO  valid result: 
recall@5 : 0.0477    recall@10 : 0.0751    recall@20 : 0.111    recall@50 : 0.1735    mrr@5 : 0.0202    mrr@10 : 0.0238    mrr@20 : 0.0262    mrr@50 : 0.0282    ndcg@5 : 0.0269    ndcg@10 : 0.0358    ndcg@20 : 0.0448    ndcg@50 : 0.0571    precision@5 : 0.0095    precision@10 : 0.0075    precision@20 : 0.0056    precision@50 : 0.0035    
Train    30: 100% 514/514 [00:36<00:00, 14.18it/s]
05 Oct 00:17    INFO  epoch 30 training [time: 36.42s, train_loss1: 3963.7200, train_loss2: 2520.8662, train_loss3: -3895.3879]
Evaluate   : 100% 88/88 [00:00<00:00, 170.94it/s]
05 Oct 00:17    INFO  epoch 30 evaluating [time: 0.65s, valid_score: 0.023400]
05 Oct 00:17    INFO  valid result: 
recall@5 : 0.0473    recall@10 : 0.0759    recall@20 : 0.1091    recall@50 : 0.1727    mrr@5 : 0.0196    mrr@10 : 0.0234    mrr@20 : 0.0257    mrr@50 : 0.0277    ndcg@5 : 0.0264    ndcg@10 : 0.0357    ndcg@20 : 0.044    ndcg@50 : 0.0566    precision@5 : 0.0095    precision@10 : 0.0076    precision@20 : 0.0055    precision@50 : 0.0035    
Train    31: 100% 514/514 [00:36<00:00, 13.92it/s]
05 Oct 00:17    INFO  epoch 31 training [time: 37.10s, train_loss1: 3957.8117, train_loss2: 2515.0288, train_loss3: -3875.3307]
Evaluate   : 100% 88/88 [00:00<00:00, 171.94it/s]
05 Oct 00:17    INFO  epoch 31 evaluating [time: 0.65s, valid_score: 0.022700]
05 Oct 00:17    INFO  valid result: 
recall@5 : 0.0462    recall@10 : 0.0751    recall@20 : 0.1079    recall@50 : 0.1711    mrr@5 : 0.0188    mrr@10 : 0.0227    mrr@20 : 0.0249    mrr@50 : 0.0269    ndcg@5 : 0.0256    ndcg@10 : 0.0349    ndcg@20 : 0.0432    ndcg@50 : 0.0557    precision@5 : 0.0092    precision@10 : 0.0075    precision@20 : 0.0054    precision@50 : 0.0034    
Train    32: 100% 514/514 [00:36<00:00, 14.00it/s]
05 Oct 00:18    INFO  epoch 32 training [time: 36.89s, train_loss1: 3950.9663, train_loss2: 2504.4312, train_loss3: -3857.3646]
Evaluate   : 100% 88/88 [00:00<00:00, 169.33it/s]
05 Oct 00:18    INFO  epoch 32 evaluating [time: 0.75s, valid_score: 0.023700]
05 Oct 00:18    INFO  valid result: 
recall@5 : 0.0487    recall@10 : 0.077    recall@20 : 0.1102    recall@50 : 0.1731    mrr@5 : 0.02    mrr@10 : 0.0237    mrr@20 : 0.026    mrr@50 : 0.028    ndcg@5 : 0.0271    ndcg@10 : 0.0362    ndcg@20 : 0.0445    ndcg@50 : 0.057    precision@5 : 0.0097    precision@10 : 0.0077    precision@20 : 0.0055    precision@50 : 0.0035    
Train    33: 100% 514/514 [00:36<00:00, 14.03it/s]
05 Oct 00:19    INFO  epoch 33 training [time: 36.88s, train_loss1: 3943.6103, train_loss2: 2496.4897, train_loss3: -3835.9289]
Evaluate   : 100% 88/88 [00:00<00:00, 165.29it/s]
05 Oct 00:19    INFO  epoch 33 evaluating [time: 0.76s, valid_score: 0.023500]
05 Oct 00:19    INFO  valid result: 
recall@5 : 0.0482    recall@10 : 0.0766    recall@20 : 0.1094    recall@50 : 0.17    mrr@5 : 0.0198    mrr@10 : 0.0235    mrr@20 : 0.0258    mrr@50 : 0.0277    ndcg@5 : 0.0268    ndcg@10 : 0.0359    ndcg@20 : 0.0442    ndcg@50 : 0.0562    precision@5 : 0.0096    precision@10 : 0.0077    precision@20 : 0.0055    precision@50 : 0.0034    
Train    34: 100% 514/514 [00:37<00:00, 13.86it/s]
05 Oct 00:19    INFO  epoch 34 training [time: 37.32s, train_loss1: 3936.3635, train_loss2: 2487.6433, train_loss3: -3810.9324]
Evaluate   : 100% 88/88 [00:00<00:00, 161.65it/s]
05 Oct 00:19    INFO  epoch 34 evaluating [time: 0.68s, valid_score: 0.023400]
05 Oct 00:19    INFO  valid result: 
recall@5 : 0.0478    recall@10 : 0.0762    recall@20 : 0.1096    recall@50 : 0.171    mrr@5 : 0.0197    mrr@10 : 0.0234    mrr@20 : 0.0257    mrr@50 : 0.0276    ndcg@5 : 0.0266    ndcg@10 : 0.0358    ndcg@20 : 0.0441    ndcg@50 : 0.0563    precision@5 : 0.0096    precision@10 : 0.0076    precision@20 : 0.0055    precision@50 : 0.0034    
05 Oct 00:19    INFO  Finished training, best eval result in epoch 23
05 Oct 00:19    INFO  Loading model structure and parameters from /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs256-lmd0.1-sem0.1-us_x-Oct-04-2025_23-57-41-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Evaluate   : 100% 88/88 [00:00<00:00, 146.81it/s]
05 Oct 00:19    INFO  best valid : {'recall@5': np.float64(0.048), 'recall@10': np.float64(0.0759), 'recall@20': np.float64(0.11), 'recall@50': np.float64(0.1764), 'mrr@5': np.float64(0.0211), 'mrr@10': np.float64(0.0248), 'mrr@20': np.float64(0.0271), 'mrr@50': np.float64(0.0292), 'ndcg@5': np.float64(0.0277), 'ndcg@10': np.float64(0.0367), 'ndcg@20': np.float64(0.0453), 'ndcg@50': np.float64(0.0584), 'precision@5': np.float64(0.0096), 'precision@10': np.float64(0.0076), 'precision@20': np.float64(0.0055), 'precision@50': np.float64(0.0035)}
05 Oct 00:19    INFO  test result: {'recall@5': np.float64(0.0333), 'recall@10': np.float64(0.0546), 'recall@20': np.float64(0.0836), 'recall@50': np.float64(0.1376), 'mrr@5': np.float64(0.0149), 'mrr@10': np.float64(0.0177), 'mrr@20': np.float64(0.0197), 'mrr@50': np.float64(0.0214), 'ndcg@5': np.float64(0.0194), 'ndcg@10': np.float64(0.0263), 'ndcg@20': np.float64(0.0336), 'ndcg@50': np.float64(0.0442), 'precision@5': np.float64(0.0067), 'precision@10': np.float64(0.0055), 'precision@20': np.float64(0.0042), 'precision@50': np.float64(0.0028)}
