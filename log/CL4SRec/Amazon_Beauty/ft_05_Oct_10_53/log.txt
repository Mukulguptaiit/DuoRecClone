05 Oct 10:53    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = ./dataset/Amazon_Beauty
show_progress = True

Training Hyper Parameters:
checkpoint_dir = saved
epochs = 50
train_batch_size = 512
learner = adam
learning_rate = 0.001
training_neg_sample_num = 0
training_neg_sample_distribution = uniform
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0
draw_loss_pic = False
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_setting = TO_LS,full
group_by_user = True
split_ratio = [0.8, 0.1, 0.1]
leave_one_num = 2
real_time_process = False
metrics = ['Recall', 'MRR', 'NDCG', 'Precision']
topk = [5, 10, 20, 50]
valid_metric = MRR@10
eval_batch_size = 256
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}
unload_col = None
unused_col = None
additional_feat_suffix = None
lowest_val = None
highest_val = None
equal_val = None
not_equal_val = None
max_user_inter_num = None
min_user_inter_num = 5
max_item_inter_num = None
min_item_inter_num = 5
fields_in_same_space = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id

Other Hyper Parameters: 
valid_metric_bigger = True
n_layers = 2
n_heads = 2
hidden_size = 64
inner_size = 256
hidden_dropout_prob = 0.5
attn_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
loss_type = CE
lmd = 0.1
SSL_AUG = CL4SRec
rm_dup_inter = None
filter_inter_by_user_or_item = True
SOURCE_ID_FIELD = source_id
TARGET_ID_FIELD = target_id
benchmark_filename = None
MODEL_TYPE = ModelType.SEQUENTIAL
log_root = ./log/
lmd_sem = 0.1
tau = 1
contrast = us_x
sim = dot
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
device = cuda
train_neg_sample_args = {'strategy': 'none'}
log_dir = /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5


05 Oct 10:53    INFO  Amazon_Beauty
The number of users: 22364
Average actions of users: 8.876358270357287
The number of items: 12102
Average actions of items: 16.403768283612923
The number of inters: 198502
The sparsity of the dataset: 99.92665707018277%
Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']
05 Oct 10:53    INFO  Build [SequentialDataLoader] for [train] with format [InputType.POINTWISE]
05 Oct 10:53    INFO  [train] No Negative Sampling
05 Oct 10:53    INFO  [train] batch_size = [512], shuffle = [True]

05 Oct 10:53    INFO  Build [SequentialFullDataLoader] for [evaluation] with format [InputType.POINTWISE]
05 Oct 10:53    INFO  Evaluation Setting:
	Group by user_id
	Ordering: {'strategy': 'by', 'field': 'timestamp', 'ascending': True}
	Splitting: {'strategy': 'loo', 'leave_one_num': 2}
	Negative Sampling: {'strategy': 'full', 'distribution': 'uniform'}
05 Oct 10:53    INFO  [evaluation] batch_size = [256], shuffle = [False]

05 Oct 10:53    INFO  CL4SRec(
  (item_embedding): Embedding(12103, 64, padding_idx=0)
  (position_embedding): Embedding(50, 64)
  (trm_encoder): TransformerEncoder(
    (layer): ModuleList(
      (0-1): 2 x TransformerLayer(
        (multi_head_attention): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (loss_fct): CrossEntropyLoss()
  (nce_fct): CrossEntropyLoss()
)
Trainable parameters: 877888
Train     0: 100% 257/257 [00:40<00:00,  6.39it/s]
05 Oct 10:54    INFO  epoch 0 training [time: 40.44s, train_loss1: 2491.6679, train_loss2: 1401.5769, train_loss3: -2998.8566]
Evaluate   : 100% 88/88 [00:00<00:00, 156.30it/s]
05 Oct 10:54    INFO  epoch 0 evaluating [time: 0.72s, valid_score: 0.007000]
05 Oct 10:54    INFO  valid result: 
recall@5 : 0.0123    recall@10 : 0.0218    recall@20 : 0.0316    recall@50 : 0.0508    mrr@5 : 0.0058    mrr@10 : 0.007    mrr@20 : 0.0077    mrr@50 : 0.0082    ndcg@5 : 0.0074    ndcg@10 : 0.0104    ndcg@20 : 0.0129    ndcg@50 : 0.0166    precision@5 : 0.0025    precision@10 : 0.0022    precision@20 : 0.0016    precision@50 : 0.001    
05 Oct 10:54    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     1: 100% 257/257 [00:39<00:00,  6.58it/s]
05 Oct 10:54    INFO  epoch 1 training [time: 39.19s, train_loss1: 2339.9040, train_loss2: 1202.1326, train_loss3: -2829.7466]
Evaluate   : 100% 88/88 [00:00<00:00, 168.19it/s]
05 Oct 10:54    INFO  epoch 1 evaluating [time: 0.66s, valid_score: 0.009000]
05 Oct 10:54    INFO  valid result: 
recall@5 : 0.0168    recall@10 : 0.0275    recall@20 : 0.0408    recall@50 : 0.0694    mrr@5 : 0.0075    mrr@10 : 0.009    mrr@20 : 0.0099    mrr@50 : 0.0108    ndcg@5 : 0.0098    ndcg@10 : 0.0133    ndcg@20 : 0.0166    ndcg@50 : 0.0223    precision@5 : 0.0034    precision@10 : 0.0027    precision@20 : 0.002    precision@50 : 0.0014    
05 Oct 10:54    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     2: 100% 257/257 [00:37<00:00,  6.77it/s]
05 Oct 10:55    INFO  epoch 2 training [time: 38.10s, train_loss1: 2274.7241, train_loss2: 1204.6825, train_loss3: -2880.8255]
Evaluate   : 100% 88/88 [00:00<00:00, 167.44it/s]
05 Oct 10:55    INFO  epoch 2 evaluating [time: 0.67s, valid_score: 0.011100]
05 Oct 10:55    INFO  valid result: 
recall@5 : 0.0196    recall@10 : 0.0351    recall@20 : 0.055    recall@50 : 0.0915    mrr@5 : 0.009    mrr@10 : 0.0111    mrr@20 : 0.0125    mrr@50 : 0.0136    ndcg@5 : 0.0116    ndcg@10 : 0.0166    ndcg@20 : 0.0217    ndcg@50 : 0.0289    precision@5 : 0.0039    precision@10 : 0.0035    precision@20 : 0.0027    precision@50 : 0.0018    
05 Oct 10:55    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     3: 100% 257/257 [00:38<00:00,  6.66it/s]
05 Oct 10:56    INFO  epoch 3 training [time: 38.81s, train_loss1: 2224.6856, train_loss2: 1227.6445, train_loss3: -2942.3000]
Evaluate   : 100% 88/88 [00:00<00:00, 163.69it/s]
05 Oct 10:56    INFO  epoch 3 evaluating [time: 0.68s, valid_score: 0.013200]
05 Oct 10:56    INFO  valid result: 
recall@5 : 0.0223    recall@10 : 0.0399    recall@20 : 0.0641    recall@50 : 0.1107    mrr@5 : 0.0109    mrr@10 : 0.0132    mrr@20 : 0.0148    mrr@50 : 0.0163    ndcg@5 : 0.0137    ndcg@10 : 0.0193    ndcg@20 : 0.0254    ndcg@50 : 0.0346    precision@5 : 0.0045    precision@10 : 0.004    precision@20 : 0.0032    precision@50 : 0.0022    
05 Oct 10:56    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     4: 100% 257/257 [00:38<00:00,  6.74it/s]
05 Oct 10:56    INFO  epoch 4 training [time: 38.31s, train_loss1: 2185.9691, train_loss2: 1251.8376, train_loss3: -2991.7596]
Evaluate   : 100% 88/88 [00:00<00:00, 167.19it/s]
05 Oct 10:56    INFO  epoch 4 evaluating [time: 0.66s, valid_score: 0.015000]
05 Oct 10:56    INFO  valid result: 
recall@5 : 0.0255    recall@10 : 0.0453    recall@20 : 0.0714    recall@50 : 0.1199    mrr@5 : 0.0124    mrr@10 : 0.015    mrr@20 : 0.0168    mrr@50 : 0.0184    ndcg@5 : 0.0156    ndcg@10 : 0.022    ndcg@20 : 0.0286    ndcg@50 : 0.0382    precision@5 : 0.0051    precision@10 : 0.0045    precision@20 : 0.0036    precision@50 : 0.0024    
05 Oct 10:56    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     5: 100% 257/257 [00:38<00:00,  6.73it/s]
05 Oct 10:57    INFO  epoch 5 training [time: 38.36s, train_loss1: 2157.7500, train_loss2: 1271.3943, train_loss3: -2999.0820]
Evaluate   : 100% 88/88 [00:00<00:00, 165.03it/s]
05 Oct 10:57    INFO  epoch 5 evaluating [time: 0.68s, valid_score: 0.016900]
05 Oct 10:57    INFO  valid result: 
recall@5 : 0.0303    recall@10 : 0.0502    recall@20 : 0.0763    recall@50 : 0.1285    mrr@5 : 0.0143    mrr@10 : 0.0169    mrr@20 : 0.0187    mrr@50 : 0.0203    ndcg@5 : 0.0183    ndcg@10 : 0.0246    ndcg@20 : 0.0312    ndcg@50 : 0.0414    precision@5 : 0.0061    precision@10 : 0.005    precision@20 : 0.0038    precision@50 : 0.0026    
05 Oct 10:57    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     6: 100% 257/257 [00:38<00:00,  6.63it/s]
05 Oct 10:57    INFO  epoch 6 training [time: 38.93s, train_loss1: 2138.4352, train_loss2: 1280.3383, train_loss3: -2950.7425]
Evaluate   : 100% 88/88 [00:00<00:00, 165.86it/s]
05 Oct 10:57    INFO  epoch 6 evaluating [time: 0.67s, valid_score: 0.017700]
05 Oct 10:57    INFO  valid result: 
recall@5 : 0.0313    recall@10 : 0.0522    recall@20 : 0.079    recall@50 : 0.1377    mrr@5 : 0.0149    mrr@10 : 0.0177    mrr@20 : 0.0195    mrr@50 : 0.0213    ndcg@5 : 0.0189    ndcg@10 : 0.0257    ndcg@20 : 0.0324    ndcg@50 : 0.044    precision@5 : 0.0063    precision@10 : 0.0052    precision@20 : 0.004    precision@50 : 0.0028    
05 Oct 10:57    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     7: 100% 257/257 [00:38<00:00,  6.62it/s]
05 Oct 10:58    INFO  epoch 7 training [time: 38.98s, train_loss1: 2124.6826, train_loss2: 1284.8875, train_loss3: -2882.1033]
Evaluate   : 100% 88/88 [00:00<00:00, 162.74it/s]
05 Oct 10:58    INFO  epoch 7 evaluating [time: 0.68s, valid_score: 0.018500]
05 Oct 10:58    INFO  valid result: 
recall@5 : 0.0333    recall@10 : 0.0537    recall@20 : 0.0832    recall@50 : 0.1412    mrr@5 : 0.0159    mrr@10 : 0.0185    mrr@20 : 0.0205    mrr@50 : 0.0223    ndcg@5 : 0.0202    ndcg@10 : 0.0267    ndcg@20 : 0.0341    ndcg@50 : 0.0455    precision@5 : 0.0067    precision@10 : 0.0054    precision@20 : 0.0042    precision@50 : 0.0028    
05 Oct 10:58    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     8: 100% 257/257 [00:38<00:00,  6.73it/s]
05 Oct 10:59    INFO  epoch 8 training [time: 38.37s, train_loss1: 2114.0541, train_loss2: 1289.7326, train_loss3: -2786.6637]
Evaluate   : 100% 88/88 [00:00<00:00, 167.27it/s]
05 Oct 10:59    INFO  epoch 8 evaluating [time: 0.67s, valid_score: 0.019700]
05 Oct 10:59    INFO  valid result: 
recall@5 : 0.0358    recall@10 : 0.0565    recall@20 : 0.0887    recall@50 : 0.1476    mrr@5 : 0.017    mrr@10 : 0.0197    mrr@20 : 0.0219    mrr@50 : 0.0237    ndcg@5 : 0.0216    ndcg@10 : 0.0283    ndcg@20 : 0.0363    ndcg@50 : 0.0479    precision@5 : 0.0072    precision@10 : 0.0057    precision@20 : 0.0044    precision@50 : 0.003    
05 Oct 10:59    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train     9: 100% 257/257 [00:39<00:00,  6.56it/s]
05 Oct 10:59    INFO  epoch 9 training [time: 39.33s, train_loss1: 2108.1340, train_loss2: 1292.6099, train_loss3: -2692.2539]
Evaluate   : 100% 88/88 [00:00<00:00, 166.51it/s]
05 Oct 10:59    INFO  epoch 9 evaluating [time: 0.66s, valid_score: 0.020300]
05 Oct 10:59    INFO  valid result: 
recall@5 : 0.0362    recall@10 : 0.0585    recall@20 : 0.0903    recall@50 : 0.1526    mrr@5 : 0.0174    mrr@10 : 0.0203    mrr@20 : 0.0225    mrr@50 : 0.0245    ndcg@5 : 0.022    ndcg@10 : 0.0292    ndcg@20 : 0.0372    ndcg@50 : 0.0495    precision@5 : 0.0072    precision@10 : 0.0059    precision@20 : 0.0045    precision@50 : 0.0031    
05 Oct 10:59    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    10: 100% 257/257 [00:39<00:00,  6.55it/s]
05 Oct 11:00    INFO  epoch 10 training [time: 39.43s, train_loss1: 2102.5379, train_loss2: 1290.5238, train_loss3: -2608.7540]
Evaluate   : 100% 88/88 [00:00<00:00, 161.24it/s]
05 Oct 11:00    INFO  epoch 10 evaluating [time: 0.76s, valid_score: 0.019600]
05 Oct 11:00    INFO  valid result: 
recall@5 : 0.0353    recall@10 : 0.0599    recall@20 : 0.0929    recall@50 : 0.1556    mrr@5 : 0.0164    mrr@10 : 0.0196    mrr@20 : 0.0219    mrr@50 : 0.0238    ndcg@5 : 0.021    ndcg@10 : 0.029    ndcg@20 : 0.0372    ndcg@50 : 0.0496    precision@5 : 0.0071    precision@10 : 0.006    precision@20 : 0.0046    precision@50 : 0.0031    
Train    11: 100% 257/257 [00:39<00:00,  6.58it/s]
05 Oct 11:01    INFO  epoch 11 training [time: 39.26s, train_loss1: 2099.4400, train_loss2: 1288.4071, train_loss3: -2525.1860]
Evaluate   : 100% 88/88 [00:00<00:00, 165.01it/s]
05 Oct 11:01    INFO  epoch 11 evaluating [time: 0.68s, valid_score: 0.020500]
05 Oct 11:01    INFO  valid result: 
recall@5 : 0.0362    recall@10 : 0.0612    recall@20 : 0.0968    recall@50 : 0.1577    mrr@5 : 0.0172    mrr@10 : 0.0205    mrr@20 : 0.023    mrr@50 : 0.0249    ndcg@5 : 0.0219    ndcg@10 : 0.0299    ndcg@20 : 0.0389    ndcg@50 : 0.0509    precision@5 : 0.0072    precision@10 : 0.0061    precision@20 : 0.0048    precision@50 : 0.0032    
05 Oct 11:01    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    12: 100% 257/257 [00:38<00:00,  6.68it/s]
05 Oct 11:01    INFO  epoch 12 training [time: 38.65s, train_loss1: 2095.5175, train_loss2: 1287.9097, train_loss3: -2451.4361]
Evaluate   : 100% 88/88 [00:00<00:00, 167.32it/s]
05 Oct 11:01    INFO  epoch 12 evaluating [time: 0.68s, valid_score: 0.022100]
05 Oct 11:01    INFO  valid result: 
recall@5 : 0.0391    recall@10 : 0.064    recall@20 : 0.0996    recall@50 : 0.164    mrr@5 : 0.0189    mrr@10 : 0.0221    mrr@20 : 0.0245    mrr@50 : 0.0266    ndcg@5 : 0.0238    ndcg@10 : 0.0318    ndcg@20 : 0.0408    ndcg@50 : 0.0535    precision@5 : 0.0078    precision@10 : 0.0064    precision@20 : 0.005    precision@50 : 0.0033    
05 Oct 11:01    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    13: 100% 257/257 [00:38<00:00,  6.67it/s]
05 Oct 11:02    INFO  epoch 13 training [time: 38.72s, train_loss1: 2092.0458, train_loss2: 1287.7104, train_loss3: -2398.7922]
Evaluate   : 100% 88/88 [00:00<00:00, 167.55it/s]
05 Oct 11:02    INFO  epoch 13 evaluating [time: 0.68s, valid_score: 0.021400]
05 Oct 11:02    INFO  valid result: 
recall@5 : 0.0395    recall@10 : 0.0648    recall@20 : 0.1    recall@50 : 0.1651    mrr@5 : 0.0181    mrr@10 : 0.0214    mrr@20 : 0.0238    mrr@50 : 0.0259    ndcg@5 : 0.0234    ndcg@10 : 0.0315    ndcg@20 : 0.0403    ndcg@50 : 0.0532    precision@5 : 0.0079    precision@10 : 0.0065    precision@20 : 0.005    precision@50 : 0.0033    
Train    14: 100% 257/257 [00:38<00:00,  6.62it/s]
05 Oct 11:03    INFO  epoch 14 training [time: 39.03s, train_loss1: 2089.9356, train_loss2: 1287.8527, train_loss3: -2349.1705]
Evaluate   : 100% 88/88 [00:00<00:00, 162.34it/s]
05 Oct 11:03    INFO  epoch 14 evaluating [time: 0.79s, valid_score: 0.021500]
05 Oct 11:03    INFO  valid result: 
recall@5 : 0.0394    recall@10 : 0.0655    recall@20 : 0.102    recall@50 : 0.1671    mrr@5 : 0.0181    mrr@10 : 0.0215    mrr@20 : 0.024    mrr@50 : 0.0261    ndcg@5 : 0.0233    ndcg@10 : 0.0317    ndcg@20 : 0.0409    ndcg@50 : 0.0537    precision@5 : 0.0079    precision@10 : 0.0066    precision@20 : 0.0051    precision@50 : 0.0033    
Train    15: 100% 257/257 [00:39<00:00,  6.51it/s]
05 Oct 11:03    INFO  epoch 15 training [time: 39.75s, train_loss1: 2086.9075, train_loss2: 1284.5665, train_loss3: -2299.5259]
Evaluate   : 100% 88/88 [00:00<00:00, 167.13it/s]
05 Oct 11:03    INFO  epoch 15 evaluating [time: 0.67s, valid_score: 0.022100]
05 Oct 11:03    INFO  valid result: 
recall@5 : 0.0397    recall@10 : 0.0669    recall@20 : 0.1026    recall@50 : 0.167    mrr@5 : 0.0185    mrr@10 : 0.0221    mrr@20 : 0.0245    mrr@50 : 0.0266    ndcg@5 : 0.0237    ndcg@10 : 0.0325    ndcg@20 : 0.0415    ndcg@50 : 0.0542    precision@5 : 0.0079    precision@10 : 0.0067    precision@20 : 0.0051    precision@50 : 0.0033    
Train    16: 100% 257/257 [00:38<00:00,  6.61it/s]
05 Oct 11:04    INFO  epoch 16 training [time: 39.06s, train_loss1: 2082.7528, train_loss2: 1284.4823, train_loss3: -2268.0513]
Evaluate   : 100% 88/88 [00:00<00:00, 168.36it/s]
05 Oct 11:04    INFO  epoch 16 evaluating [time: 0.68s, valid_score: 0.022400]
05 Oct 11:04    INFO  valid result: 
recall@5 : 0.041    recall@10 : 0.0675    recall@20 : 0.1031    recall@50 : 0.1667    mrr@5 : 0.0189    mrr@10 : 0.0224    mrr@20 : 0.0248    mrr@50 : 0.0268    ndcg@5 : 0.0243    ndcg@10 : 0.0329    ndcg@20 : 0.0418    ndcg@50 : 0.0544    precision@5 : 0.0082    precision@10 : 0.0067    precision@20 : 0.0052    precision@50 : 0.0033    
05 Oct 11:04    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    17: 100% 257/257 [00:38<00:00,  6.63it/s]
05 Oct 11:05    INFO  epoch 17 training [time: 38.94s, train_loss1: 2080.5502, train_loss2: 1284.0385, train_loss3: -2235.2780]
Evaluate   : 100% 88/88 [00:00<00:00, 166.46it/s]
05 Oct 11:05    INFO  epoch 17 evaluating [time: 0.67s, valid_score: 0.022500]
05 Oct 11:05    INFO  valid result: 
recall@5 : 0.0422    recall@10 : 0.0691    recall@20 : 0.1057    recall@50 : 0.1699    mrr@5 : 0.019    mrr@10 : 0.0225    mrr@20 : 0.025    mrr@50 : 0.027    ndcg@5 : 0.0247    ndcg@10 : 0.0333    ndcg@20 : 0.0425    ndcg@50 : 0.0551    precision@5 : 0.0084    precision@10 : 0.0069    precision@20 : 0.0053    precision@50 : 0.0034    
05 Oct 11:05    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    18: 100% 257/257 [00:39<00:00,  6.50it/s]
05 Oct 11:05    INFO  epoch 18 training [time: 39.78s, train_loss1: 2077.0488, train_loss2: 1283.4538, train_loss3: -2206.7792]
Evaluate   : 100% 88/88 [00:00<00:00, 168.03it/s]
05 Oct 11:05    INFO  epoch 18 evaluating [time: 0.68s, valid_score: 0.023000]
05 Oct 11:05    INFO  valid result: 
recall@5 : 0.0428    recall@10 : 0.0693    recall@20 : 0.1025    recall@50 : 0.1684    mrr@5 : 0.0195    mrr@10 : 0.023    mrr@20 : 0.0253    mrr@50 : 0.0274    ndcg@5 : 0.0252    ndcg@10 : 0.0338    ndcg@20 : 0.0422    ndcg@50 : 0.0552    precision@5 : 0.0086    precision@10 : 0.0069    precision@20 : 0.0051    precision@50 : 0.0034    
05 Oct 11:05    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    19: 100% 257/257 [00:38<00:00,  6.64it/s]
05 Oct 11:06    INFO  epoch 19 training [time: 38.91s, train_loss1: 2073.0890, train_loss2: 1284.7482, train_loss3: -2187.4458]
Evaluate   : 100% 88/88 [00:00<00:00, 168.82it/s]
05 Oct 11:06    INFO  epoch 19 evaluating [time: 0.71s, valid_score: 0.022900]
05 Oct 11:06    INFO  valid result: 
recall@5 : 0.0427    recall@10 : 0.0694    recall@20 : 0.1053    recall@50 : 0.1698    mrr@5 : 0.0194    mrr@10 : 0.0229    mrr@20 : 0.0254    mrr@50 : 0.0274    ndcg@5 : 0.0251    ndcg@10 : 0.0338    ndcg@20 : 0.0428    ndcg@50 : 0.0555    precision@5 : 0.0085    precision@10 : 0.0069    precision@20 : 0.0053    precision@50 : 0.0034    
Train    20: 100% 257/257 [00:39<00:00,  6.51it/s]
05 Oct 11:07    INFO  epoch 20 training [time: 39.63s, train_loss1: 2069.9160, train_loss2: 1287.0129, train_loss3: -2168.6907]
Evaluate   : 100% 88/88 [00:00<00:00, 168.62it/s]
05 Oct 11:07    INFO  epoch 20 evaluating [time: 0.66s, valid_score: 0.023700]
05 Oct 11:07    INFO  valid result: 
recall@5 : 0.0442    recall@10 : 0.0707    recall@20 : 0.1065    recall@50 : 0.1694    mrr@5 : 0.0202    mrr@10 : 0.0237    mrr@20 : 0.0262    mrr@50 : 0.0282    ndcg@5 : 0.0261    ndcg@10 : 0.0347    ndcg@20 : 0.0437    ndcg@50 : 0.0561    precision@5 : 0.0088    precision@10 : 0.0071    precision@20 : 0.0053    precision@50 : 0.0034    
05 Oct 11:07    INFO  Saving current best: /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Train    21: 100% 257/257 [00:39<00:00,  6.57it/s]
05 Oct 11:07    INFO  epoch 21 training [time: 39.30s, train_loss1: 2065.4553, train_loss2: 1285.6051, train_loss3: -2147.8408]
Evaluate   : 100% 88/88 [00:00<00:00, 168.77it/s]
05 Oct 11:07    INFO  epoch 21 evaluating [time: 0.68s, valid_score: 0.022600]
05 Oct 11:07    INFO  valid result: 
recall@5 : 0.0436    recall@10 : 0.0686    recall@20 : 0.1045    recall@50 : 0.1689    mrr@5 : 0.0194    mrr@10 : 0.0226    mrr@20 : 0.0251    mrr@50 : 0.0272    ndcg@5 : 0.0253    ndcg@10 : 0.0334    ndcg@20 : 0.0424    ndcg@50 : 0.0552    precision@5 : 0.0087    precision@10 : 0.0069    precision@20 : 0.0052    precision@50 : 0.0034    
Train    22: 100% 257/257 [00:38<00:00,  6.61it/s]
05 Oct 11:08    INFO  epoch 22 training [time: 39.08s, train_loss1: 2060.5618, train_loss2: 1287.2779, train_loss3: -2135.8575]
Evaluate   : 100% 88/88 [00:00<00:00, 167.74it/s]
05 Oct 11:08    INFO  epoch 22 evaluating [time: 0.67s, valid_score: 0.023200]
05 Oct 11:08    INFO  valid result: 
recall@5 : 0.0438    recall@10 : 0.0711    recall@20 : 0.1059    recall@50 : 0.1694    mrr@5 : 0.0196    mrr@10 : 0.0232    mrr@20 : 0.0256    mrr@50 : 0.0276    ndcg@5 : 0.0255    ndcg@10 : 0.0344    ndcg@20 : 0.0431    ndcg@50 : 0.0557    precision@5 : 0.0088    precision@10 : 0.0071    precision@20 : 0.0053    precision@50 : 0.0034    
Train    23: 100% 257/257 [00:38<00:00,  6.61it/s]
05 Oct 11:09    INFO  epoch 23 training [time: 39.07s, train_loss1: 2056.7675, train_loss2: 1286.9500, train_loss3: -2109.7213]
Evaluate   : 100% 88/88 [00:00<00:00, 167.89it/s]
05 Oct 11:09    INFO  epoch 23 evaluating [time: 0.67s, valid_score: 0.023300]
05 Oct 11:09    INFO  valid result: 
recall@5 : 0.0442    recall@10 : 0.0703    recall@20 : 0.1062    recall@50 : 0.1704    mrr@5 : 0.0198    mrr@10 : 0.0233    mrr@20 : 0.0257    mrr@50 : 0.0278    ndcg@5 : 0.0258    ndcg@10 : 0.0342    ndcg@20 : 0.0433    ndcg@50 : 0.056    precision@5 : 0.0088    precision@10 : 0.007    precision@20 : 0.0053    precision@50 : 0.0034    
Train    24: 100% 257/257 [00:39<00:00,  6.57it/s]
05 Oct 11:09    INFO  epoch 24 training [time: 39.28s, train_loss1: 2051.5974, train_loss2: 1288.8160, train_loss3: -2105.1471]
Evaluate   : 100% 88/88 [00:00<00:00, 149.24it/s]
05 Oct 11:09    INFO  epoch 24 evaluating [time: 0.83s, valid_score: 0.023300]
05 Oct 11:09    INFO  valid result: 
recall@5 : 0.0444    recall@10 : 0.0712    recall@20 : 0.1058    recall@50 : 0.1702    mrr@5 : 0.0198    mrr@10 : 0.0233    mrr@20 : 0.0256    mrr@50 : 0.0277    ndcg@5 : 0.0259    ndcg@10 : 0.0345    ndcg@20 : 0.0431    ndcg@50 : 0.0559    precision@5 : 0.0089    precision@10 : 0.0071    precision@20 : 0.0053    precision@50 : 0.0034    
Train    25: 100% 257/257 [00:38<00:00,  6.59it/s]
05 Oct 11:10    INFO  epoch 25 training [time: 39.23s, train_loss1: 2047.0320, train_loss2: 1291.1961, train_loss3: -2092.3511]
Evaluate   : 100% 88/88 [00:00<00:00, 168.22it/s]
05 Oct 11:10    INFO  epoch 25 evaluating [time: 0.68s, valid_score: 0.023300]
05 Oct 11:10    INFO  valid result: 
recall@5 : 0.0442    recall@10 : 0.0716    recall@20 : 0.1083    recall@50 : 0.1704    mrr@5 : 0.0196    mrr@10 : 0.0233    mrr@20 : 0.0258    mrr@50 : 0.0278    ndcg@5 : 0.0257    ndcg@10 : 0.0345    ndcg@20 : 0.0438    ndcg@50 : 0.0561    precision@5 : 0.0088    precision@10 : 0.0072    precision@20 : 0.0054    precision@50 : 0.0034    
Train    26: 100% 257/257 [00:38<00:00,  6.68it/s]
05 Oct 11:11    INFO  epoch 26 training [time: 38.64s, train_loss1: 2041.8860, train_loss2: 1290.2612, train_loss3: -2071.2892]
Evaluate   : 100% 88/88 [00:00<00:00, 169.22it/s]
05 Oct 11:11    INFO  epoch 26 evaluating [time: 0.67s, valid_score: 0.023200]
05 Oct 11:11    INFO  valid result: 
recall@5 : 0.0448    recall@10 : 0.071    recall@20 : 0.105    recall@50 : 0.1687    mrr@5 : 0.0198    mrr@10 : 0.0232    mrr@20 : 0.0256    mrr@50 : 0.0276    ndcg@5 : 0.0259    ndcg@10 : 0.0344    ndcg@20 : 0.0429    ndcg@50 : 0.0555    precision@5 : 0.009    precision@10 : 0.0071    precision@20 : 0.0052    precision@50 : 0.0034    
Train    27: 100% 257/257 [00:38<00:00,  6.63it/s]
05 Oct 11:11    INFO  epoch 27 training [time: 38.95s, train_loss1: 2037.8304, train_loss2: 1291.3369, train_loss3: -2067.3543]
Evaluate   : 100% 88/88 [00:00<00:00, 168.62it/s]
05 Oct 11:11    INFO  epoch 27 evaluating [time: 0.67s, valid_score: 0.023500]
05 Oct 11:11    INFO  valid result: 
recall@5 : 0.0445    recall@10 : 0.0725    recall@20 : 0.1063    recall@50 : 0.1691    mrr@5 : 0.0198    mrr@10 : 0.0235    mrr@20 : 0.0258    mrr@50 : 0.0278    ndcg@5 : 0.0259    ndcg@10 : 0.0349    ndcg@20 : 0.0434    ndcg@50 : 0.0558    precision@5 : 0.0089    precision@10 : 0.0072    precision@20 : 0.0053    precision@50 : 0.0034    
Train    28: 100% 257/257 [00:39<00:00,  6.59it/s]
05 Oct 11:12    INFO  epoch 28 training [time: 39.20s, train_loss1: 2032.9439, train_loss2: 1292.9194, train_loss3: -2056.7899]
Evaluate   : 100% 88/88 [00:00<00:00, 159.28it/s]
05 Oct 11:12    INFO  epoch 28 evaluating [time: 0.78s, valid_score: 0.023000]
05 Oct 11:12    INFO  valid result: 
recall@5 : 0.0452    recall@10 : 0.0715    recall@20 : 0.1057    recall@50 : 0.1667    mrr@5 : 0.0195    mrr@10 : 0.023    mrr@20 : 0.0254    mrr@50 : 0.0273    ndcg@5 : 0.0258    ndcg@10 : 0.0343    ndcg@20 : 0.0429    ndcg@50 : 0.055    precision@5 : 0.009    precision@10 : 0.0072    precision@20 : 0.0053    precision@50 : 0.0033    
Train    29: 100% 257/257 [00:39<00:00,  6.55it/s]
05 Oct 11:13    INFO  epoch 29 training [time: 39.44s, train_loss1: 2028.7165, train_loss2: 1290.9061, train_loss3: -2045.5987]
Evaluate   : 100% 88/88 [00:00<00:00, 168.87it/s]
05 Oct 11:13    INFO  epoch 29 evaluating [time: 0.66s, valid_score: 0.022500]
05 Oct 11:13    INFO  valid result: 
recall@5 : 0.0454    recall@10 : 0.0719    recall@20 : 0.1068    recall@50 : 0.1676    mrr@5 : 0.019    mrr@10 : 0.0225    mrr@20 : 0.0249    mrr@50 : 0.0268    ndcg@5 : 0.0255    ndcg@10 : 0.034    ndcg@20 : 0.0428    ndcg@50 : 0.0548    precision@5 : 0.0091    precision@10 : 0.0072    precision@20 : 0.0053    precision@50 : 0.0034    
Train    30: 100% 257/257 [00:38<00:00,  6.72it/s]
05 Oct 11:13    INFO  epoch 30 training [time: 38.41s, train_loss1: 2025.3383, train_loss2: 1291.2507, train_loss3: -2031.6871]
Evaluate   : 100% 88/88 [00:00<00:00, 168.33it/s]
05 Oct 11:13    INFO  epoch 30 evaluating [time: 0.67s, valid_score: 0.022700]
05 Oct 11:13    INFO  valid result: 
recall@5 : 0.0456    recall@10 : 0.0714    recall@20 : 0.1053    recall@50 : 0.1663    mrr@5 : 0.0193    mrr@10 : 0.0227    mrr@20 : 0.025    mrr@50 : 0.027    ndcg@5 : 0.0258    ndcg@10 : 0.0341    ndcg@20 : 0.0426    ndcg@50 : 0.0547    precision@5 : 0.0091    precision@10 : 0.0071    precision@20 : 0.0053    precision@50 : 0.0033    
Train    31: 100% 257/257 [00:38<00:00,  6.73it/s]
05 Oct 11:14    INFO  epoch 31 training [time: 38.34s, train_loss1: 2020.1633, train_loss2: 1291.1252, train_loss3: -2028.1632]
Evaluate   : 100% 88/88 [00:00<00:00, 168.94it/s]
05 Oct 11:14    INFO  epoch 31 evaluating [time: 0.66s, valid_score: 0.022600]
05 Oct 11:14    INFO  valid result: 
recall@5 : 0.045    recall@10 : 0.0711    recall@20 : 0.1054    recall@50 : 0.165    mrr@5 : 0.0191    mrr@10 : 0.0226    mrr@20 : 0.0249    mrr@50 : 0.0268    ndcg@5 : 0.0255    ndcg@10 : 0.0339    ndcg@20 : 0.0425    ndcg@50 : 0.0543    precision@5 : 0.009    precision@10 : 0.0071    precision@20 : 0.0053    precision@50 : 0.0033    
05 Oct 11:14    INFO  Finished training, best eval result in epoch 20
05 Oct 11:14    INFO  Loading model structure and parameters from /content/DuoRec/log/CL4SRec/Amazon_Beauty/bs512-lmd0.1-sem0.1-us_x-Oct-05-2025_10-53-02-lr0.001-l20-tau1-dot-DPh0.5-DPa0.5/model.pth
Evaluate   : 100% 88/88 [00:00<00:00, 153.34it/s]
05 Oct 11:14    INFO  best valid : {'recall@5': np.float64(0.0442), 'recall@10': np.float64(0.0707), 'recall@20': np.float64(0.1065), 'recall@50': np.float64(0.1694), 'mrr@5': np.float64(0.0202), 'mrr@10': np.float64(0.0237), 'mrr@20': np.float64(0.0262), 'mrr@50': np.float64(0.0282), 'ndcg@5': np.float64(0.0261), 'ndcg@10': np.float64(0.0347), 'ndcg@20': np.float64(0.0437), 'ndcg@50': np.float64(0.0561), 'precision@5': np.float64(0.0088), 'precision@10': np.float64(0.0071), 'precision@20': np.float64(0.0053), 'precision@50': np.float64(0.0034)}
05 Oct 11:14    INFO  test result: {'recall@5': np.float64(0.0302), 'recall@10': np.float64(0.05), 'recall@20': np.float64(0.0781), 'recall@50': np.float64(0.1301), 'mrr@5': np.float64(0.0146), 'mrr@10': np.float64(0.0172), 'mrr@20': np.float64(0.0191), 'mrr@50': np.float64(0.0207), 'ndcg@5': np.float64(0.0184), 'ndcg@10': np.float64(0.0248), 'ndcg@20': np.float64(0.0319), 'ndcg@50': np.float64(0.0421), 'precision@5': np.float64(0.006), 'precision@10': np.float64(0.005), 'precision@20': np.float64(0.0039), 'precision@50': np.float64(0.0026)}
